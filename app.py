import gradio as gr
import subprocess
import tempfile
import os
import shutil
from pathlib import Path
import torch
import torchaudio
import numpy as np
from df import enhance, init_df
import logging
import warnings

# ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§
warnings.filterwarnings("ignore", category=UserWarning, module="torchaudio")
warnings.filterwarnings("ignore", category=UserWarning, module="df")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class VideoAudioEnhancer:
    def __init__(self):
        """DeepFilterNet ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            logger.info("DeepFilterNet ëª¨ë¸ ë¡œë”© ì¤‘...")
            self.model, self.df_state, _ = init_df()
            logger.info("DeepFilterNet ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        except Exception as e:
            logger.error(f"DeepFilterNet ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            self.model = None
            self.df_state = None
    
    def extract_audio_from_video(self, video_path, audio_path):
        """1ë‹¨ê³„: ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ (FFmpeg ì‚¬ìš©)"""
        try:
            cmd = [
                'ffmpeg', '-i', video_path,
                '-vn',  # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì œì™¸
                '-acodec', 'pcm_s16le',  # WAV í¬ë§·
                '-ar', '48000',  # 48kHz ìƒ˜í”Œë§ ë ˆì´íŠ¸ (DeepFilterNet ìš”êµ¬ì‚¬í•­)
                '-ac', '1',  # ëª¨ë…¸ë¡œ ë³€í™˜
                '-y',  # ë®ì–´ì“°ê¸°
                audio_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            logger.info(f"ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ: {audio_path}")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {e.stderr}")
            return False
    
    def convert_mono_to_stereo(self, mono_audio_path, stereo_audio_path):
        """ëª¨ë…¸ ì˜¤ë””ì˜¤ë¥¼ ìŠ¤í…Œë ˆì˜¤ë¡œ ë³€í™˜ (ì–‘ìª½ ì±„ë„ì— ë™ì¼í•œ ì†Œë¦¬)"""
        try:
            cmd = [
                'ffmpeg', '-i', mono_audio_path,
                '-ac', '2',  # ìŠ¤í…Œë ˆì˜¤ë¡œ ë³€í™˜
                '-af', 'pan=stereo|c0=c0|c1=c0',  # ëª¨ë…¸ ì±„ë„ì„ ì–‘ìª½ìœ¼ë¡œ ë³µì‚¬
                '-y',  # ë®ì–´ì“°ê¸°
                stereo_audio_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            logger.info(f"ìŠ¤í…Œë ˆì˜¤ ë³€í™˜ ì™„ë£Œ: {stereo_audio_path}")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"ìŠ¤í…Œë ˆì˜¤ ë³€í™˜ ì‹¤íŒ¨: {e.stderr}")
            return False
    
    def enhance_audio_with_deepfilter(self, input_audio_path, output_audio_path):
        """2ë‹¨ê³„: DeepFilterNetìœ¼ë¡œ ì˜¤ë””ì˜¤ ì •ì œ"""
        try:
            if self.model is None or self.df_state is None:
                raise Exception("DeepFilterNet ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            try:
                # ì˜¤ë””ì˜¤ ë¡œë“œ ì‹œë„
                audio, sr = torchaudio.load(input_audio_path)
            except Exception as e:
                logger.warning(f"torchaudio ë¡œë“œ ì‹¤íŒ¨, librosaë¡œ ì‹œë„: {e}")
                # librosaë¥¼ ë°±ì—…ìœ¼ë¡œ ì‚¬ìš©
                import librosa
                audio_np, sr = librosa.load(input_audio_path, sr=None, mono=False)
                audio = torch.from_numpy(audio_np)
                if len(audio.shape) == 1:
                    audio = audio.unsqueeze(0)
            
            # 48kHzê°€ ì•„ë‹Œ ê²½ìš° ë¦¬ìƒ˜í”Œë§
            if sr != 48000:
                resampler = torchaudio.transforms.Resample(sr, 48000)
                audio = resampler(audio)
                sr = 48000
            
            # ëª¨ë…¸ë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
            if audio.shape[0] > 1:
                audio = torch.mean(audio, dim=0, keepdim=True)
            
            # DeepFilterNetì€ [channels, samples] í˜•íƒœë¥¼ ê¸°ëŒ€í•¨
            if len(audio.shape) == 1:
                audio = audio.unsqueeze(0)
            
            logger.info(f"ì²˜ë¦¬ ì „ ì˜¤ë””ì˜¤ í˜•íƒœ: {audio.shape}, ìƒ˜í”Œë ˆì´íŠ¸: {sr}")
            
            # ê¸´ ì˜¤ë””ì˜¤ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)
            chunk_size = 48000 * 30  # 30ì´ˆ ì²­í¬
            total_samples = audio.shape[1]
            
            if total_samples > chunk_size:
                logger.info(f"ê¸´ ì˜¤ë””ì˜¤ ê°ì§€ ({total_samples/48000:.1f}ì´ˆ). ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                enhanced_chunks = []
                
                for i in range(0, total_samples, chunk_size):
                    end_idx = min(i + chunk_size, total_samples)
                    chunk = audio[:, i:end_idx]
                    
                    # ë©”ëª¨ë¦¬ ì •ë¦¬
                    torch.cuda.empty_cache() if torch.cuda.is_available() else None
                    
                    logger.info(f"ì²­í¬ {i//chunk_size + 1} ì²˜ë¦¬ ì¤‘... ({i/48000:.1f}s - {end_idx/48000:.1f}s)")
                    
                    try:
                        # ê° ì²­í¬ë¥¼ contiguousí•˜ê²Œ ë§Œë“¤ê¸°
                        chunk = chunk.contiguous()
                        
                        with torch.no_grad():
                            enhanced_chunk = enhance(self.model, self.df_state, chunk)
                        
                        # CPUë¡œ ì´ë™í•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½
                        if isinstance(enhanced_chunk, torch.Tensor):
                            enhanced_chunk = enhanced_chunk.cpu()
                        
                        enhanced_chunks.append(enhanced_chunk)
                        
                    except Exception as e:
                        logger.warning(f"ì²­í¬ {i//chunk_size + 1} GPU ì²˜ë¦¬ ì‹¤íŒ¨, CPUë¡œ ì‹œë„: {e}")
                        # CPUë¡œ í´ë°±
                        try:
                            # ëª¨ë¸ì„ CPUë¡œ ì´ë™
                            cpu_model, cpu_df_state, _ = init_df()
                            if hasattr(cpu_model, 'cpu'):
                                cpu_model = cpu_model.cpu()
                            
                            chunk_cpu = chunk.cpu()
                            with torch.no_grad():
                                enhanced_chunk = enhance(cpu_model, cpu_df_state, chunk_cpu)
                            
                            enhanced_chunks.append(enhanced_chunk)
                            
                        except Exception as cpu_e:
                            logger.error(f"CPU ì²˜ë¦¬ë„ ì‹¤íŒ¨: {cpu_e}")
                            # ì›ë³¸ ì²­í¬ ì‚¬ìš© (ì²˜ë¦¬ ì‹¤íŒ¨ì‹œ)
                            enhanced_chunks.append(chunk.squeeze())
                
                # ëª¨ë“  ì²­í¬ ê²°í•©
                if isinstance(enhanced_chunks[0], torch.Tensor):
                    enhanced_audio = torch.cat(enhanced_chunks, dim=-1)
                else:
                    enhanced_audio = np.concatenate(enhanced_chunks, axis=-1)
                
                logger.info(f"ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ. ì´ {len(enhanced_chunks)}ê°œ ì²­í¬ ë³‘í•©")
                
            else:
                # ì§§ì€ ì˜¤ë””ì˜¤ëŠ” í•œ ë²ˆì— ì²˜ë¦¬
                try:
                    # ë©”ëª¨ë¦¬ ì—°ì†ì„± í™•ë³´
                    audio = audio.contiguous()
                    
                    with torch.no_grad():
                        enhanced_audio = enhance(self.model, self.df_state, audio)
                        
                except Exception as e:
                    logger.warning(f"GPU ì²˜ë¦¬ ì‹¤íŒ¨, CPUë¡œ í´ë°±: {e}")
                    # CPU í´ë°±
                    cpu_model, cpu_df_state, _ = init_df()
                    if hasattr(cpu_model, 'cpu'):
                        cpu_model = cpu_model.cpu()
                    
                    audio_cpu = audio.cpu()
                    with torch.no_grad():
                        enhanced_audio = enhance(cpu_model, cpu_df_state, audio_cpu)
            
            logger.info(f"ì²˜ë¦¬ í›„ ì˜¤ë””ì˜¤ í˜•íƒœ: {enhanced_audio.shape if hasattr(enhanced_audio, 'shape') else type(enhanced_audio)}")
            
            # ê²°ê³¼ ì €ì¥ ì¤€ë¹„
            if isinstance(enhanced_audio, torch.Tensor):
                if len(enhanced_audio.shape) == 1:
                    enhanced_tensor = enhanced_audio.unsqueeze(0)
                else:
                    enhanced_tensor = enhanced_audio
            else:
                # numpy ë°°ì—´ì¸ ê²½ìš°
                if len(enhanced_audio.shape) == 1:
                    enhanced_tensor = torch.from_numpy(enhanced_audio).unsqueeze(0)
                else:
                    enhanced_tensor = torch.from_numpy(enhanced_audio)
            
            # ì €ì¥ ì‹œë„
            try:
                torchaudio.save(output_audio_path, enhanced_tensor, sr)
                logger.info(f"torchaudioë¡œ ì €ì¥ ì„±ê³µ: {output_audio_path}")
            except Exception as e:
                logger.warning(f"torchaudio ì €ì¥ ì‹¤íŒ¨, soundfileë¡œ ì‹œë„: {e}")
                import soundfile as sf
                if isinstance(enhanced_audio, torch.Tensor):
                    audio_to_save = enhanced_audio.squeeze().cpu().numpy()
                else:
                    audio_to_save = enhanced_audio.squeeze() if enhanced_audio.ndim > 1 else enhanced_audio
                sf.write(output_audio_path, audio_to_save, sr)
                logger.info(f"soundfileë¡œ ì €ì¥ ì„±ê³µ: {output_audio_path}")
            
            logger.info(f"ì˜¤ë””ì˜¤ ì •ì œ ì™„ë£Œ: {output_audio_path}")
            return True
            
        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ì •ì œ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def replace_audio_in_video(self, original_video_path, enhanced_audio_path, output_video_path):
        """3ë‹¨ê³„: ì •ì œëœ ì˜¤ë””ì˜¤ë¥¼ ì›ë³¸ ì˜ìƒì— ì‚½ì…"""
        try:
            cmd = [
                'ffmpeg', '-i', original_video_path,
                '-i', enhanced_audio_path,
                '-c:v', 'copy',  # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ë³µì‚¬ (ì¬ì¸ì½”ë”© ì—†ìŒ)
                '-c:a', 'aac',   # ì˜¤ë””ì˜¤ë¥¼ AACë¡œ ì¸ì½”ë”©
                '-map', '0:v:0',  # ì²« ë²ˆì§¸ ì…ë ¥ì˜ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼
                '-map', '1:a:0',  # ë‘ ë²ˆì§¸ ì…ë ¥ì˜ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼
                '-shortest',      # ê°€ì¥ ì§§ì€ ìŠ¤íŠ¸ë¦¼ì— ë§ì¶¤
                '-y',             # ë®ì–´ì“°ê¸°
                output_video_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            logger.info(f"ì˜ìƒ ìƒì„± ì™„ë£Œ: {output_video_path}")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {e.stderr}")
            return False

# ì „ì—­ enhancer ì¸ìŠ¤í„´ìŠ¤
enhancer = VideoAudioEnhancer()

def process_video(video_file, use_postfilter=False, convert_to_stereo=False):
    """ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜"""
    if video_file is None:
        return None, "ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
    
    try:
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_dir = Path(temp_dir)
            
            # íŒŒì¼ ê²½ë¡œ ì„¤ì •
            input_video_path = temp_dir / "input_video.mp4"
            extracted_audio_path = temp_dir / "extracted_audio.wav"
            enhanced_audio_path = temp_dir / "enhanced_audio.wav"
            stereo_audio_path = temp_dir / "stereo_audio.wav"
            output_video_path = temp_dir / "output_video.mp4"
            
            # ì…ë ¥ íŒŒì¼ ë³µì‚¬
            shutil.copy2(video_file, input_video_path)
            
            status_msg = "ğŸ¬ ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘..."
            
            # 1ë‹¨ê³„: ì˜¤ë””ì˜¤ ì¶”ì¶œ
            if not enhancer.extract_audio_from_video(str(input_video_path), str(extracted_audio_path)):
                return None, "âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            
            status_msg += "\nâœ… ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ\nğŸ§ DeepFilterNetìœ¼ë¡œ ìŒì„± ì •ì œ ì¤‘..."
            
            # 2ë‹¨ê³„: ì˜¤ë””ì˜¤ ì •ì œ
            if not enhancer.enhance_audio_with_deepfilter(str(extracted_audio_path), str(enhanced_audio_path)):
                return None, "âŒ ì˜¤ë””ì˜¤ ì •ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            
            status_msg += "\nâœ… ìŒì„± ì •ì œ ì™„ë£Œ"
            
            # ì„ íƒì‚¬í•­: ìŠ¤í…Œë ˆì˜¤ ë³€í™˜
            final_audio_path = enhanced_audio_path
            if convert_to_stereo:
                status_msg += "\nğŸ”Š ëª¨ë…¸ ì˜¤ë””ì˜¤ë¥¼ ìŠ¤í…Œë ˆì˜¤ë¡œ ë³€í™˜ ì¤‘..."
                if not enhancer.convert_mono_to_stereo(str(enhanced_audio_path), str(stereo_audio_path)):
                    return None, "âŒ ìŠ¤í…Œë ˆì˜¤ ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                final_audio_path = stereo_audio_path
                status_msg += "\nâœ… ìŠ¤í…Œë ˆì˜¤ ë³€í™˜ ì™„ë£Œ"
            
            status_msg += "\nğŸ“¼ ì •ì œëœ ì˜¤ë””ì˜¤ë¥¼ ì˜ìƒì— ì‚½ì… ì¤‘..."
            
            # 3ë‹¨ê³„: ì˜ìƒì— ì˜¤ë””ì˜¤ ì‚½ì…
            if not enhancer.replace_audio_in_video(str(input_video_path), str(final_audio_path), str(output_video_path)):
                return None, "âŒ ì˜ìƒ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            
            status_msg += "\nâœ… ì˜ìƒ ìƒì„± ì™„ë£Œ!"
            
            # ê²°ê³¼ íŒŒì¼ì„ ì„ì‹œ ìœ„ì¹˜ì—ì„œ ë³µì‚¬
            final_output_path = f"enhanced_{Path(video_file).stem}.mp4"
            shutil.copy2(output_video_path, final_output_path)
            
            return final_output_path, status_msg
            
    except Exception as e:
        logger.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
def create_interface():
    with gr.Blocks(title="ğŸ¬ Video Audio Enhancement with DeepFilterNet", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸ¬ ì˜ìƒ ìŒì„± í–¥ìƒ ë„êµ¬
        
        DeepFilterNet3ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒì˜ ë°°ê²½ ì†ŒìŒì„ ì œê±°í•˜ê³  ìŒì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
        
        ## ğŸ“‹ ì²˜ë¦¬ ê³¼ì •
        1. **ğŸ¥ ì˜¤ë””ì˜¤ ì¶”ì¶œ**: ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ë¥¼ WAV í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œ
        2. **ğŸ§ ìŒì„± ì •ì œ**: DeepFilterNet3ë¡œ ë°°ê²½ ì†ŒìŒ ì œê±° ë° ìŒì„± í–¥ìƒ
        3. **ğŸ“¼ ì˜ìƒ ìƒì„±**: ì •ì œëœ ì˜¤ë””ì˜¤ë¥¼ ì›ë³¸ ì˜ìƒì— ì‚½ì…í•˜ì—¬ ìƒˆë¡œìš´ ì˜ìƒ ìƒì„±
        
        ## ğŸ“ ì§€ì› í˜•ì‹
        - **ì…ë ¥**: MP4, AVI, MOV, MKV ë“± ëŒ€ë¶€ë¶„ì˜ ì˜ìƒ í˜•ì‹
        - **ì¶œë ¥**: MP4 (H.264 ë¹„ë””ì˜¤ + AAC ì˜¤ë””ì˜¤)
        """)
        
        with gr.Row():
            with gr.Column():
                video_input = gr.File(
                    label="ğŸ“ ì˜ìƒ íŒŒì¼ ì—…ë¡œë“œ",
                    file_types=["video"],
                    file_count="single"
                )
                
                postfilter_checkbox = gr.Checkbox(
                    label="ğŸ”§ í¬ìŠ¤íŠ¸í•„í„° ì‚¬ìš© (ë§¤ìš° ì‹œë„ëŸ¬ìš´ ì„¹ì…˜ ì¶”ê°€ ê°ì‡ )",
                    value=False
                )
                
                stereo_checkbox = gr.Checkbox(
                    label="ğŸ”Š ëª¨ë…¸ â†’ ìŠ¤í…Œë ˆì˜¤ ë³€í™˜ (í•œìª½ ì†Œë¦¬ë¥¼ ì–‘ìª½ìœ¼ë¡œ)",
                    value=False,
                    info="í•œìª½ ì´ì–´í°/ìŠ¤í”¼ì»¤ì—ì„œë§Œ ë“¤ë¦¬ëŠ” ì†Œë¦¬ë¥¼ ì–‘ìª½ì—ì„œ ë“¤ë¦¬ê²Œ ë§Œë“­ë‹ˆë‹¤"
                )
                
                process_btn = gr.Button(
                    "ğŸš€ ì˜ìƒ ì²˜ë¦¬ ì‹œì‘",
                    variant="primary",
                    size="lg"
                )
            
            with gr.Column():
                status_output = gr.Textbox(
                    label="ğŸ“Š ì²˜ë¦¬ ìƒíƒœ",
                    lines=8,
                    interactive=False
                )
                
                video_output = gr.File(
                    label="ğŸ“¥ ì²˜ë¦¬ëœ ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
                    interactive=False
                )
        
        # ì˜ˆì œ ì„¹ì…˜
        gr.Markdown("""
        ## ğŸ’¡ ì‚¬ìš© íŒ
        - **ìµœì  ì„±ëŠ¥**: 48kHz ìƒ˜í”Œë§ ë ˆì´íŠ¸ì˜ ì˜¤ë””ì˜¤ê°€ í¬í•¨ëœ ì˜ìƒì„ ì‚¬ìš©í•˜ì„¸ìš”
        - **ì²˜ë¦¬ ì‹œê°„**: ì˜ìƒ ê¸¸ì´ì— ë”°ë¼ ëª‡ ë¶„ì—ì„œ ìˆ˜ì‹­ ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        - **GPU ê°€ì†**: CUDAê°€ ì„¤ì¹˜ëœ í™˜ê²½ì—ì„œëŠ” GPUë¥¼ ìë™ìœ¼ë¡œ í™œìš©í•©ë‹ˆë‹¤
        
        ## âš ï¸ ì£¼ì˜ì‚¬í•­
        - FFmpegê°€ ì‹œìŠ¤í…œì— ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤
        - DeepFilterNet ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤
        - ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì‹œ ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ì„ í™•ë³´í•´ì£¼ì„¸ìš”
        """)
        
        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        process_btn.click(
            fn=process_video,
            inputs=[video_input, postfilter_checkbox, stereo_checkbox],
            outputs=[video_output, status_output],
            show_progress=True
        )
        
        return demo

# ì˜ì¡´ì„± í™•ì¸ í•¨ìˆ˜
def check_dependencies():
    """í•„ìš”í•œ ì˜ì¡´ì„± í™•ì¸"""
    dependencies = {
        'ffmpeg': 'FFmpeg (ì˜ìƒ/ì˜¤ë””ì˜¤ ì²˜ë¦¬)',
        'deepfilternet': 'DeepFilterNet (ìŒì„± í–¥ìƒ)',
        'torch': 'PyTorch (ë”¥ëŸ¬ë‹)',
        'torchaudio': 'TorchAudio (ì˜¤ë””ì˜¤ ì²˜ë¦¬)'
    }
    
    missing = []
    
    # FFmpeg í™•ì¸
    try:
        subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        missing.append('ffmpeg')
    
    # Python íŒ¨í‚¤ì§€ í™•ì¸
    try:
        import torch
        import torchaudio
        from df import enhance, init_df
    except ImportError as e:
        missing.append(str(e))
    
    if missing:
        print("âŒ ë‹¤ìŒ ì˜ì¡´ì„±ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤:")
        for dep in missing:
            print(f"   - {dep}")
        print("\nì„¤ì¹˜ ë°©ë²•:")
        print("pip install torch torchaudio deepfilternet")
        print("FFmpeg: https://ffmpeg.org/download.html")
        return False
    
    print("âœ… ëª¨ë“  ì˜ì¡´ì„±ì´ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    return True

if __name__ == "__main__":
    print("ğŸ¬ Video Audio Enhancement with DeepFilterNet")
    print("=" * 50)
    
    # ì˜ì¡´ì„± í™•ì¸
    if not check_dependencies():
        exit(1)
    
    # Gradio ì•± ì‹¤í–‰
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        debug=True
    )